{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from initial_plots import read_dataset\n",
    "import numpy as np\n",
    "from whole_pipeline import *\n",
    "from utils_torch import *\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    cols overlap represents how many cols we precede before starting a new patch\\n    for example for a 1x9 grid with 1X3 patches and cols_overlap = 2:\\n    (1 2 [3) 4 (5] 6 [7) 8 9]\\n    similar to rows overlap\\n\\n    idealy, to prevent data loss overlap should be 1\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = read_dataset(gt=False)\n",
    "\n",
    "X = np.array(df)\n",
    "X = X.reshape((610,340, 103))\n",
    "\n",
    "df = read_dataset(gt=True)\n",
    "y = np.array(df)\n",
    "\n",
    "rows_factor=28\n",
    "cols_factor=28\n",
    "\n",
    "#insert rows_overlap = -1 or cols_overlapp = -1 to avoid overlapping\n",
    "rows_overlap=21\n",
    "cols_overlap=21\n",
    "\n",
    "\"\"\"\n",
    "    cols overlap represents how many cols we precede before starting a new patch\n",
    "    for example for a 1x9 grid with 1X3 patches and cols_overlap = 2:\n",
    "    (1 2 [3) 4 (5] 6 [7) 8 9]\n",
    "    similar to rows overlap\n",
    "\n",
    "    idealy, to prevent data loss overlap should be 1\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old version- using whole X as data\n",
    "# whole_pipeline_all(X,y, rows_factor, cols_factor, is_normalize_each_band=True, method_label_patch='center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XXXXXXX IN METHOD XXXXXXXXX\n",
      "PREPARE TIME:  1.3164341449737549\n",
      "HDE TIME:  0.4150691032409668\n",
      "HDD TIME:  0.3347318172454834\n",
      "WHOLE METHOD TIME:  2.068812608718872\n",
      "XXXXXXX IN CLASSIFICATION XXXXXXXXX\n",
      "DICT CREATION, THROW 0 LABELS, SPLIT TETS TRAIN TIME:  0.0019981861114501953\n",
      "patch_to_points_dict:  {0: (21, 49, 168, 196), 1: (42, 70, 126, 154), 2: (42, 70, 147, 175), 3: (84, 112, 42, 70), 4: (84, 112, 105, 133), 5: (84, 112, 147, 175), 6: (105, 133, 21, 49), 7: (105, 133, 63, 91), 8: (105, 133, 84, 112), 9: (105, 133, 168, 196), 10: (126, 154, 42, 70), 11: (126, 154, 168, 196), 12: (147, 175, 21, 49), 13: (147, 175, 168, 196), 14: (147, 175, 189, 217), 15: (168, 196, 21, 49), 16: (168, 196, 42, 70), 17: (168, 196, 63, 91), 18: (168, 196, 84, 112), 19: (168, 196, 189, 217), 20: (189, 217, 84, 112), 21: (210, 238, 42, 70), 22: (210, 238, 105, 133), 23: (210, 238, 147, 175), 24: (210, 238, 168, 196), 25: (231, 259, 84, 112), 26: (231, 259, 105, 133), 27: (231, 259, 168, 196), 28: (231, 259, 210, 238), 29: (252, 280, 126, 154), 30: (252, 280, 168, 196), 31: (273, 301, 231, 259), 32: (294, 322, 84, 112), 33: (294, 322, 189, 217), 34: (294, 322, 210, 238), 35: (294, 322, 336, 364), 36: (315, 343, 21, 49), 37: (315, 343, 147, 175), 38: (315, 343, 168, 196), 39: (315, 343, 189, 217), 40: (315, 343, 210, 238), 41: (336, 364, 21, 49), 42: (336, 364, 126, 154), 43: (336, 364, 168, 196), 44: (336, 364, 189, 217), 45: (336, 364, 210, 238), 46: (336, 364, 231, 259), 47: (357, 385, 147, 175), 48: (357, 385, 189, 217), 49: (357, 385, 210, 238), 50: (378, 406, 42, 70), 51: (378, 406, 147, 175), 52: (378, 406, 168, 196), 53: (378, 406, 294, 322), 54: (399, 427, 42, 70), 55: (420, 448, 21, 49), 56: (420, 448, 147, 175), 57: (441, 469, 105, 133), 58: (441, 469, 336, 364), 59: (462, 490, 84, 112), 60: (462, 490, 105, 133), 61: (462, 490, 231, 259), 62: (504, 532, 63, 91), 63: (504, 532, 210, 238), 64: (504, 532, 231, 259), 65: (525, 553, 21, 49), 66: (525, 553, 63, 91), 67: (525, 553, 105, 133), 68: (525, 553, 210, 238), 69: (525, 553, 231, 259), 70: (546, 574, 84, 112), 71: (546, 574, 189, 217), 72: (546, 574, 210, 238), 73: (546, 574, 231, 259), 74: (546, 574, 252, 280), 75: (567, 595, 63, 91), 76: (567, 595, 84, 112), 77: (567, 595, 147, 175), 78: (567, 595, 189, 217), 79: (567, 595, 210, 238), 80: (567, 595, 231, 259), 81: (567, 595, 252, 280), 82: (588, 616, 21, 49), 83: (588, 616, 63, 91), 84: (588, 616, 168, 196), 85: (588, 616, 189, 217), 86: (588, 616, 210, 238), 87: (588, 616, 231, 259), 88: (588, 616, 252, 280), 89: (588, 616, 273, 301), 90: (609, 637, 21, 49), 91: (609, 637, 42, 70), 92: (609, 637, 63, 91), 93: (609, 637, 84, 112), 94: (609, 637, 105, 133), 95: (609, 637, 126, 154), 96: (609, 637, 147, 175), 97: (609, 637, 168, 196), 98: (609, 637, 189, 217), 99: (609, 637, 210, 238), 100: (609, 637, 231, 259), 101: (609, 637, 252, 280), 102: (609, 637, 273, 301)}\n",
      "labels:  [4 1 2 2 1 2 4 2 1 4 8 8 8 2 1 2 8 2 5 5 2 5 1 1 8 6 6 4 3 7 7 6 3 7 6 6 7\n",
      " 6 3 7 1 9 3 1 9 1 4 8 2 2 8 8 2 8 2 2 2 8 8 1 2 2 2 2 2 1 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2]\n",
      "Number of patches:  82\n",
      "Number of patches:  21\n",
      "Train Accuracy:  0.8048780487804879\n",
      "Test Accuracy:  0.7142857142857143\n",
      "SCORES TIME:  0.0019979476928710938\n",
      "WHOLE CLASSIFICATION TIME:  0.005000114440917969\n"
     ]
    }
   ],
   "source": [
    "# old version- using whole X as data\n",
    "whole_pipeline_all_torch(torch.from_numpy(X),torch.from_numpy(y), rows_factor, cols_factor, rows_overlap, cols_overlap, is_normalize_each_band=True, method_label_patch='center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new version- dividing X to spectral bands\n",
    "#whole_pipeline_divided(X,y, rows_factor, cols_factor, is_normalize_each_band=True, method_label_patch='center')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]])\n",
      "PREPARE TIME:  0.0795142650604248\n",
      "HDE TIME:  0.46914219856262207\n",
      "HDD TIME:  0.3049960136413574\n",
      "PREPARE TIME:  0.08752226829528809\n",
      "HDE TIME:  0.37006163597106934\n",
      "HDD TIME:  0.22844243049621582\n",
      "PREPARE TIME:  0.0590057373046875\n",
      "HDE TIME:  0.29039549827575684\n",
      "HDD TIME:  0.26019287109375\n",
      "PREPARE TIME:  0.05401349067687988\n",
      "HDE TIME:  0.26720476150512695\n",
      "HDD TIME:  0.19885921478271484\n",
      "PREPARE TIME:  0.04351806640625\n",
      "HDE TIME:  0.26588010787963867\n",
      "HDD TIME:  0.19707083702087402\n",
      "PREPARE TIME:  0.07053208351135254\n",
      "HDE TIME:  0.3353309631347656\n",
      "HDD TIME:  0.24866509437561035\n",
      "PREPARE TIME:  0.04955720901489258\n",
      "HDE TIME:  0.4261741638183594\n",
      "HDD TIME:  0.2829279899597168\n",
      "PREPARE TIME:  0.06456875801086426\n",
      "HDE TIME:  0.35546231269836426\n",
      "HDD TIME:  0.23067164421081543\n",
      "PREPARE TIME:  0.06455063819885254\n",
      "HDE TIME:  0.3256227970123291\n",
      "HDD TIME:  0.4038848876953125\n",
      "PREPARE TIME:  0.06655025482177734\n",
      "HDE TIME:  0.42187976837158203\n",
      "HDD TIME:  0.33838558197021484\n",
      "PREPARE TIME:  0.07656478881835938\n",
      "HDE TIME:  0.37291860580444336\n",
      "HDD TIME:  0.22431707382202148\n",
      "PREPARE TIME:  0.045001983642578125\n",
      "HDE TIME:  0.27060770988464355\n",
      "HDD TIME:  0.3538196086883545\n",
      "PREPARE TIME:  0.07700037956237793\n",
      "HDE TIME:  0.36919617652893066\n",
      "HDD TIME:  0.34551548957824707\n",
      "PREPARE TIME:  0.12207198143005371\n",
      "HDE TIME:  0.3836033344268799\n",
      "HDD TIME:  0.270068883895874\n",
      "PREPARE TIME:  0.06772851943969727\n",
      "HDE TIME:  0.2745833396911621\n",
      "HDD TIME:  0.2299365997314453\n",
      "PREPARE TIME:  0.05258440971374512\n",
      "HDE TIME:  0.29328036308288574\n",
      "HDD TIME:  0.20912933349609375\n",
      "PREPARE TIME:  0.05350017547607422\n",
      "HDE TIME:  0.2966654300689697\n",
      "HDD TIME:  0.23723602294921875\n",
      "PREPARE TIME:  0.053223371505737305\n",
      "HDE TIME:  0.28297901153564453\n",
      "HDD TIME:  0.19632411003112793\n",
      "PREPARE TIME:  0.05366706848144531\n",
      "HDE TIME:  0.2947683334350586\n",
      "HDD TIME:  0.27417755126953125\n",
      "PREPARE TIME:  0.0607151985168457\n",
      "HDE TIME:  0.3059046268463135\n",
      "HDD TIME:  0.2342395782470703\n",
      "PREPARE TIME:  0.05871939659118652\n",
      "HDE TIME:  0.3465540409088135\n",
      "HDD TIME:  0.23596477508544922\n",
      "PREPARE TIME:  0.06224203109741211\n",
      "HDE TIME:  0.2889103889465332\n",
      "HDD TIME:  0.20142722129821777\n",
      "PREPARE TIME:  0.05729246139526367\n",
      "HDE TIME:  0.28110790252685547\n",
      "HDD TIME:  0.22515487670898438\n",
      "PREPARE TIME:  0.05633687973022461\n",
      "HDE TIME:  0.33147644996643066\n",
      "HDD TIME:  0.29308247566223145\n",
      "PREPARE TIME:  0.09885001182556152\n",
      "HDE TIME:  0.3439810276031494\n",
      "HDD TIME:  0.24105596542358398\n",
      "PREPARE TIME:  0.06352400779724121\n",
      "HDE TIME:  0.30751705169677734\n",
      "HDD TIME:  0.1900639533996582\n",
      "PREPARE TIME:  0.04000258445739746\n",
      "HDE TIME:  0.297025203704834\n",
      "HDD TIME:  0.18304133415222168\n",
      "PREPARE TIME:  0.051508188247680664\n",
      "HDE TIME:  0.2536008358001709\n",
      "HDD TIME:  0.1950066089630127\n",
      "PREPARE TIME:  0.06410646438598633\n",
      "HDE TIME:  0.3070659637451172\n",
      "HDD TIME:  0.20003771781921387\n",
      "PREPARE TIME:  0.05500459671020508\n",
      "HDE TIME:  0.2618694305419922\n",
      "HDD TIME:  0.1940624713897705\n",
      "PREPARE TIME:  0.05652427673339844\n",
      "HDE TIME:  0.279888391494751\n",
      "HDD TIME:  0.2285759449005127\n",
      "PREPARE TIME:  0.05806779861450195\n",
      "HDE TIME:  0.2822544574737549\n",
      "HDD TIME:  0.21496105194091797\n",
      "PREPARE TIME:  0.047525644302368164\n",
      "HDE TIME:  0.3403487205505371\n",
      "HDD TIME:  0.21606850624084473\n",
      "PREPARE TIME:  0.0455324649810791\n",
      "HDE TIME:  0.2740654945373535\n",
      "HDD TIME:  0.1954045295715332\n",
      "PREPARE TIME:  0.05750560760498047\n",
      "HDE TIME:  0.2706155776977539\n",
      "HDD TIME:  0.19352412223815918\n",
      "PREPARE TIME:  0.05500078201293945\n",
      "HDE TIME:  0.27758193016052246\n",
      "HDD TIME:  0.19906401634216309\n",
      "PREPARE TIME:  0.04401063919067383\n",
      "HDE TIME:  0.28911828994750977\n",
      "HDD TIME:  0.2317352294921875\n",
      "PREPARE TIME:  0.0429990291595459\n",
      "HDE TIME:  0.27089977264404297\n",
      "HDD TIME:  0.18605685234069824\n",
      "PREPARE TIME:  0.04600071907043457\n",
      "HDE TIME:  0.25624966621398926\n",
      "HDD TIME:  0.20106077194213867\n",
      "PREPARE TIME:  0.0440363883972168\n",
      "HDE TIME:  0.27988314628601074\n",
      "HDD TIME:  0.20105767250061035\n",
      "PREPARE TIME:  0.05408811569213867\n",
      "HDE TIME:  0.2752828598022461\n",
      "HDD TIME:  0.2495265007019043\n",
      "PREPARE TIME:  0.07548904418945312\n",
      "HDE TIME:  0.26374125480651855\n",
      "HDD TIME:  0.19872641563415527\n",
      "PREPARE TIME:  0.055530548095703125\n",
      "HDE TIME:  0.26575469970703125\n",
      "HDD TIME:  0.19803977012634277\n",
      "PREPARE TIME:  0.050518035888671875\n",
      "HDE TIME:  0.277923583984375\n",
      "HDD TIME:  0.20508432388305664\n",
      "PREPARE TIME:  0.05203104019165039\n",
      "HDE TIME:  0.25577545166015625\n",
      "HDD TIME:  0.1920793056488037\n",
      "PREPARE TIME:  0.0680382251739502\n",
      "HDE TIME:  0.3094339370727539\n",
      "HDD TIME:  0.20356440544128418\n",
      "PREPARE TIME:  0.05076789855957031\n",
      "HDE TIME:  0.2726311683654785\n",
      "HDD TIME:  0.18776679039001465\n",
      "PREPARE TIME:  0.05529141426086426\n",
      "HDE TIME:  0.2825894355773926\n",
      "HDD TIME:  0.1998276710510254\n",
      "PREPARE TIME:  0.04963850975036621\n",
      "HDE TIME:  0.27599668502807617\n",
      "HDD TIME:  0.20186662673950195\n",
      "PREPARE TIME:  0.05354785919189453\n",
      "HDE TIME:  0.3182952404022217\n",
      "HDD TIME:  0.2100353240966797\n",
      "PREPARE TIME:  0.04951930046081543\n",
      "HDE TIME:  0.25107669830322266\n",
      "HDD TIME:  0.19907569885253906\n",
      "PREPARE TIME:  0.04716682434082031\n",
      "HDE TIME:  0.28243350982666016\n",
      "HDD TIME:  0.20088934898376465\n",
      "PREPARE TIME:  0.05055403709411621\n",
      "HDE TIME:  0.272230863571167\n",
      "HDD TIME:  0.19572806358337402\n",
      "PREPARE TIME:  0.05096626281738281\n",
      "HDE TIME:  0.2850351333618164\n",
      "HDD TIME:  0.2276918888092041\n",
      "PREPARE TIME:  0.05251955986022949\n",
      "HDE TIME:  0.261066198348999\n",
      "HDD TIME:  0.19691181182861328\n",
      "PREPARE TIME:  0.05449676513671875\n",
      "HDE TIME:  0.27399206161499023\n",
      "HDD TIME:  0.20395708084106445\n",
      "PREPARE TIME:  0.043004751205444336\n",
      "HDE TIME:  0.26532769203186035\n",
      "HDD TIME:  0.19824814796447754\n",
      "PREPARE TIME:  0.05400395393371582\n",
      "HDE TIME:  0.27971577644348145\n",
      "HDD TIME:  0.3158700466156006\n",
      "PREPARE TIME:  0.07846951484680176\n",
      "HDE TIME:  0.2633810043334961\n",
      "HDD TIME:  0.19281673431396484\n",
      "PREPARE TIME:  0.05785179138183594\n",
      "HDE TIME:  0.2878091335296631\n",
      "HDD TIME:  0.1941218376159668\n",
      "PREPARE TIME:  0.0555572509765625\n",
      "HDE TIME:  0.2879927158355713\n",
      "HDD TIME:  0.2061765193939209\n",
      "PREPARE TIME:  0.04296422004699707\n",
      "HDE TIME:  0.233320951461792\n",
      "HDD TIME:  0.21515154838562012\n",
      "PREPARE TIME:  0.060398101806640625\n",
      "HDE TIME:  0.3169398307800293\n",
      "HDD TIME:  0.22010040283203125\n",
      "PREPARE TIME:  0.06051349639892578\n",
      "HDE TIME:  0.28423523902893066\n",
      "HDD TIME:  0.19286608695983887\n",
      "PREPARE TIME:  0.05804705619812012\n",
      "HDE TIME:  0.27864813804626465\n",
      "HDD TIME:  0.21450495719909668\n",
      "PREPARE TIME:  0.0525209903717041\n",
      "HDE TIME:  0.2825803756713867\n",
      "HDD TIME:  0.22493839263916016\n",
      "PREPARE TIME:  0.07497501373291016\n",
      "HDE TIME:  0.31096887588500977\n",
      "HDD TIME:  0.19811272621154785\n",
      "PREPARE TIME:  0.05500984191894531\n",
      "HDE TIME:  0.2582283020019531\n",
      "HDD TIME:  0.19713211059570312\n",
      "PREPARE TIME:  0.05907559394836426\n",
      "HDE TIME:  0.27095866203308105\n",
      "HDD TIME:  0.20605254173278809\n",
      "PREPARE TIME:  0.046518802642822266\n",
      "HDE TIME:  0.25763583183288574\n",
      "HDD TIME:  0.19967174530029297\n",
      "PREPARE TIME:  0.052683353424072266\n",
      "HDE TIME:  0.30449938774108887\n",
      "HDD TIME:  0.20408153533935547\n",
      "PREPARE TIME:  0.056206703186035156\n",
      "HDE TIME:  0.2772226333618164\n",
      "HDD TIME:  0.20004892349243164\n",
      "PREPARE TIME:  0.05652952194213867\n",
      "HDE TIME:  0.252962589263916\n",
      "HDD TIME:  0.1870865821838379\n",
      "PREPARE TIME:  0.04952383041381836\n",
      "HDE TIME:  0.2531552314758301\n",
      "HDD TIME:  0.1860496997833252\n",
      "PREPARE TIME:  0.05251812934875488\n",
      "HDE TIME:  0.28427720069885254\n",
      "HDD TIME:  0.23546910285949707\n",
      "PREPARE TIME:  0.0440061092376709\n",
      "HDE TIME:  0.28365492820739746\n",
      "HDD TIME:  0.18702912330627441\n",
      "PREPARE TIME:  0.04852294921875\n",
      "HDE TIME:  0.2614719867706299\n",
      "HDD TIME:  0.19803285598754883\n",
      "PREPARE TIME:  0.04651665687561035\n",
      "HDE TIME:  0.2693817615509033\n",
      "HDD TIME:  0.20446205139160156\n",
      "PREPARE TIME:  0.05950427055358887\n",
      "HDE TIME:  0.3088648319244385\n",
      "HDD TIME:  0.2680652141571045\n",
      "PREPARE TIME:  0.06695270538330078\n",
      "HDE TIME:  0.292583703994751\n",
      "HDD TIME:  0.20940113067626953\n",
      "PREPARE TIME:  0.044515132904052734\n",
      "HDE TIME:  0.2615811824798584\n",
      "HDD TIME:  0.18941617012023926\n",
      "PREPARE TIME:  0.05151510238647461\n",
      "HDE TIME:  0.270585298538208\n",
      "HDD TIME:  0.19218230247497559\n",
      "PREPARE TIME:  0.053002119064331055\n",
      "HDE TIME:  0.25963354110717773\n",
      "HDD TIME:  0.19785046577453613\n",
      "PREPARE TIME:  0.06265139579772949\n",
      "HDE TIME:  0.3102912902832031\n",
      "HDD TIME:  0.18898701667785645\n",
      "PREPARE TIME:  0.05550956726074219\n",
      "HDE TIME:  0.2826521396636963\n",
      "HDD TIME:  0.19772100448608398\n",
      "PREPARE TIME:  0.04199838638305664\n",
      "HDE TIME:  0.27957630157470703\n",
      "HDD TIME:  0.19060254096984863\n",
      "PREPARE TIME:  0.04798626899719238\n",
      "HDE TIME:  0.27767491340637207\n",
      "HDD TIME:  0.18865323066711426\n",
      "PREPARE TIME:  0.05852866172790527\n",
      "HDE TIME:  0.3696897029876709\n",
      "HDD TIME:  0.21606755256652832\n",
      "PREPARE TIME:  0.04150724411010742\n",
      "HDE TIME:  0.2576172351837158\n",
      "HDD TIME:  0.2014002799987793\n",
      "PREPARE TIME:  0.047032833099365234\n",
      "HDE TIME:  0.254077672958374\n",
      "HDD TIME:  0.18781185150146484\n",
      "PREPARE TIME:  0.0505218505859375\n",
      "HDE TIME:  0.2601907253265381\n",
      "HDD TIME:  0.19663691520690918\n",
      "PREPARE TIME:  0.04252052307128906\n",
      "HDE TIME:  0.2913651466369629\n",
      "HDD TIME:  0.2381289005279541\n",
      "PREPARE TIME:  0.05052757263183594\n",
      "HDE TIME:  0.25866198539733887\n",
      "HDD TIME:  0.19986772537231445\n",
      "PREPARE TIME:  0.05826687812805176\n",
      "HDE TIME:  0.26650214195251465\n",
      "HDD TIME:  0.19901442527770996\n",
      "PREPARE TIME:  0.04553580284118652\n",
      "HDE TIME:  0.26810598373413086\n",
      "HDD TIME:  0.19316387176513672\n",
      "PREPARE TIME:  0.05196547508239746\n",
      "HDE TIME:  0.270660400390625\n",
      "HDD TIME:  0.22824573516845703\n",
      "PREPARE TIME:  0.07482743263244629\n",
      "HDE TIME:  0.286881685256958\n",
      "HDD TIME:  0.20313024520874023\n",
      "PREPARE TIME:  0.0409700870513916\n",
      "HDE TIME:  0.2731013298034668\n",
      "HDD TIME:  0.18805742263793945\n",
      "PREPARE TIME:  0.05309438705444336\n",
      "HDE TIME:  0.2856125831604004\n",
      "HDD TIME:  0.2069387435913086\n",
      "PREPARE TIME:  0.04851198196411133\n",
      "HDE TIME:  0.2591822147369385\n",
      "HDD TIME:  0.19776511192321777\n",
      "PREPARE TIME:  0.06314802169799805\n",
      "HDE TIME:  0.2975025177001953\n",
      "HDD TIME:  0.1951732635498047\n",
      "PREPARE TIME:  0.050002098083496094\n",
      "HDE TIME:  0.2796170711517334\n",
      "HDD TIME:  0.1992473602294922\n",
      "PREPARE TIME:  0.04966998100280762\n",
      "HDE TIME:  0.27196645736694336\n",
      "HDD TIME:  0.19086360931396484\n",
      "TOTAL TIME FOR METHOD:  58.330339193344116\n",
      "patch_to_points_dict:  {0: (21, 49, 168, 196), 1: (42, 70, 126, 154), 2: (42, 70, 147, 175), 3: (84, 112, 42, 70), 4: (84, 112, 105, 133), 5: (84, 112, 147, 175), 6: (105, 133, 21, 49), 7: (105, 133, 63, 91), 8: (105, 133, 84, 112), 9: (105, 133, 168, 196), 10: (126, 154, 42, 70), 11: (126, 154, 168, 196), 12: (147, 175, 21, 49), 13: (147, 175, 168, 196), 14: (147, 175, 189, 217), 15: (168, 196, 21, 49), 16: (168, 196, 42, 70), 17: (168, 196, 63, 91), 18: (168, 196, 84, 112), 19: (168, 196, 189, 217), 20: (189, 217, 84, 112), 21: (210, 238, 42, 70), 22: (210, 238, 105, 133), 23: (210, 238, 147, 175), 24: (210, 238, 168, 196), 25: (231, 259, 84, 112), 26: (231, 259, 105, 133), 27: (231, 259, 168, 196), 28: (231, 259, 210, 238), 29: (252, 280, 126, 154), 30: (252, 280, 168, 196), 31: (273, 301, 231, 259), 32: (294, 322, 84, 112), 33: (294, 322, 189, 217), 34: (294, 322, 210, 238), 35: (294, 322, 336, 364), 36: (315, 343, 21, 49), 37: (315, 343, 147, 175), 38: (315, 343, 168, 196), 39: (315, 343, 189, 217), 40: (315, 343, 210, 238), 41: (336, 364, 21, 49), 42: (336, 364, 126, 154), 43: (336, 364, 168, 196), 44: (336, 364, 189, 217), 45: (336, 364, 210, 238), 46: (336, 364, 231, 259), 47: (357, 385, 147, 175), 48: (357, 385, 189, 217), 49: (357, 385, 210, 238), 50: (378, 406, 42, 70), 51: (378, 406, 147, 175), 52: (378, 406, 168, 196), 53: (378, 406, 294, 322), 54: (399, 427, 42, 70), 55: (420, 448, 21, 49), 56: (420, 448, 147, 175), 57: (441, 469, 105, 133), 58: (441, 469, 336, 364), 59: (462, 490, 84, 112), 60: (462, 490, 105, 133), 61: (462, 490, 231, 259), 62: (504, 532, 63, 91), 63: (504, 532, 210, 238), 64: (504, 532, 231, 259), 65: (525, 553, 21, 49), 66: (525, 553, 63, 91), 67: (525, 553, 105, 133), 68: (525, 553, 210, 238), 69: (525, 553, 231, 259), 70: (546, 574, 84, 112), 71: (546, 574, 189, 217), 72: (546, 574, 210, 238), 73: (546, 574, 231, 259), 74: (546, 574, 252, 280), 75: (567, 595, 63, 91), 76: (567, 595, 84, 112), 77: (567, 595, 147, 175), 78: (567, 595, 189, 217), 79: (567, 595, 210, 238), 80: (567, 595, 231, 259), 81: (567, 595, 252, 280), 82: (588, 616, 21, 49), 83: (588, 616, 63, 91), 84: (588, 616, 168, 196), 85: (588, 616, 189, 217), 86: (588, 616, 210, 238), 87: (588, 616, 231, 259), 88: (588, 616, 252, 280), 89: (588, 616, 273, 301), 90: (609, 637, 21, 49), 91: (609, 637, 42, 70), 92: (609, 637, 63, 91), 93: (609, 637, 84, 112), 94: (609, 637, 105, 133), 95: (609, 637, 126, 154), 96: (609, 637, 147, 175), 97: (609, 637, 168, 196), 98: (609, 637, 189, 217), 99: (609, 637, 210, 238), 100: (609, 637, 231, 259), 101: (609, 637, 252, 280), 102: (609, 637, 273, 301)}\n",
      "labels:  [4 1 4 2 2 2 2 2 4 2 1 4 4 8 2 2 8 2 5 5 8 5 1 2 5 1 8 6 6 4 3 7 6 6 3 7 6\n",
      " 6 7 6 3 7 9 1 3 1 9 4 8 1 2 2 2 2 8 2 8 2 2 2 8 8 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2]\n",
      "X_kNN.shape:  (82, 309)\n",
      "Number of patches:  82\n",
      "X_kNN.shape:  (21, 309)\n",
      "Number of patches:  21\n",
      "Train Accuracy:  0.8709044474897222\n",
      "Test Accuracy:  0.7002544529262087\n"
     ]
    }
   ],
   "source": [
    "# new version- dividing X to spectral bands\n",
    "whole_pipeline_divided_torch(torch.from_numpy(X),torch.from_numpy(y), rows_factor, cols_factor, rows_overlap, cols_overlap, is_normalize_each_band=True, method_label_patch='center')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #A test for overlapping patches:\n",
    "\n",
    "# import torch\n",
    "# from utils_torch import *\n",
    "\n",
    "# def print_tensor(tensor):\n",
    "#     for row in tensor:\n",
    "#         print(' '.join([str(elem.item()).rjust(4) for elem in row]))\n",
    "\n",
    "# rows = 5\n",
    "# cols = 5\n",
    "# data = torch.randint(0, 100, (rows, cols, 1), dtype=torch.int32)\n",
    "# labels = torch.randint(0, 3, (rows, cols), dtype=torch.int32)\n",
    "# print_tensor(labels)\n",
    "\n",
    "\n",
    "# factor = 5\n",
    "# overlap = 2\n",
    "# patched_data, patched_labels, labels = patch_data_overlap_torch(data, labels, factor, factor, overlap, overlap, method_label_patch=\"center\")\n",
    "\n",
    "# print(patched_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #A test for overlapping patches:\n",
    "\n",
    "# import torch\n",
    "# from utils_torch import *\n",
    "# from classification import patch_to_points, point_to_patches, split_train_test\n",
    "\n",
    "# def print_tensor(tensor):\n",
    "#     for row in tensor:\n",
    "#         print(' '.join([str(elem.item()).rjust(4) for elem in row]))\n",
    "\n",
    "# rows = 3\n",
    "# cols = 3\n",
    "# data = torch.randint(0, 100, (rows, cols, 1), dtype=torch.int32)\n",
    "# labels = torch.randint(0, 3, (rows, cols), dtype=torch.int32)\n",
    "# print_tensor(labels)\n",
    "\n",
    "\n",
    "# factor = 2\n",
    "# overlap = 1\n",
    "# patched_data, patched_labels, labels = patch_data_overlap_torch(data, labels, factor, factor, overlap, overlap)\n",
    "\n",
    "# print(\"-----------------------\")\n",
    "# print_tensor(patched_labels)\n",
    "\n",
    "# print(\"-----------------------\")\n",
    "# dictionary = (patch_to_points(patched_labels.flatten(), factor, factor, overlap, overlap, num_patches_in_row=patched_labels.shape[1]))\n",
    "# print(dictionary)\n",
    "\n",
    "# print(\"-----------------------\")\n",
    "# dictionary = point_to_patches(dictionary)\n",
    "# print(dictionary)\n",
    "\n",
    "# print(\"-----------------------\")\n",
    "# print(split_train_test(dictionary, patched_labels.flatten())[1])\n",
    "\n",
    "# print(\"-----------------------\")\n",
    "# print(split_train_test(dictionary, patched_labels.flatten())[3])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
